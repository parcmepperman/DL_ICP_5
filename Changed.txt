Changed(
-batch_size = 16
-num_epochs = 100
-evaluate_every = 50
-checkpoint_every = 10
)

---------------------------------------------------------
2018-07-17T12:50:17.480692: step 1, loss 2.91265, acc 0.5
2018-07-17T12:50:17.553682: step 2, loss 2.54999, acc 0.625
2018-07-17T12:50:17.594052: step 3, loss 2.05476, acc 0.75
2018-07-17T12:50:17.651479: step 4, loss 1.49515, acc 0.4375
2018-07-17T12:50:17.715349: step 5, loss 0.662156, acc 0.75
2018-07-17T12:50:17.748716: step 6, loss 0.459868, acc 0.75
2018-07-17T12:50:17.783287: step 7, loss 0.604507, acc 0.875
2018-07-17T12:50:17.810626: step 8, loss 1.04387, acc 0.6875
2018-07-17T12:50:17.830545: step 9, loss 2.6171, acc 0.25
2018-07-17T12:50:17.862750: step 10, loss 0.695662, acc 0.8125
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-10

2018-07-17T12:50:18.416839: step 11, loss 1.45421, acc 0.5625
2018-07-17T12:50:18.436517: step 12, loss 0.0217154, acc 1
2018-07-17T12:50:18.468098: step 13, loss 0.520056, acc 0.8125
2018-07-17T12:50:18.497952: step 14, loss 0.76404, acc 0.6875
2018-07-17T12:50:18.514925: step 15, loss 0.0547284, acc 1
2018-07-17T12:50:18.543097: step 16, loss 0.877495, acc 0.625
2018-07-17T12:50:18.576120: step 17, loss 0.557651, acc 0.75
2018-07-17T12:50:18.596257: step 18, loss 0.150704, acc 1
2018-07-17T12:50:18.627185: step 19, loss 0.52786, acc 0.8125
2018-07-17T12:50:18.656628: step 20, loss 0.223623, acc 0.8125
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-20

2018-07-17T12:50:19.216209: step 21, loss 0.0106669, acc 1
2018-07-17T12:50:19.257471: step 22, loss 0.0319817, acc 1
2018-07-17T12:50:19.290415: step 23, loss 0.341896, acc 0.9375
2018-07-17T12:50:19.310500: step 24, loss 0.100821, acc 1
2018-07-17T12:50:19.337763: step 25, loss 0.0278446, acc 1
2018-07-17T12:50:19.371538: step 26, loss 0.0509712, acc 1
2018-07-17T12:50:19.392415: step 27, loss 0.0237965, acc 1
2018-07-17T12:50:19.426082: step 28, loss 0.0149314, acc 1
2018-07-17T12:50:19.457173: step 29, loss 0.0601216, acc 1
2018-07-17T12:50:19.478276: step 30, loss 0.268769, acc 0.75
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-30

2018-07-17T12:50:20.276162: step 31, loss 0.0665114, acc 1
2018-07-17T12:50:20.309711: step 32, loss 0.0665845, acc 0.9375
2018-07-17T12:50:20.333822: step 33, loss 0.000235439, acc 1
2018-07-17T12:50:20.366404: step 34, loss 0.00763689, acc 1
2018-07-17T12:50:20.398880: step 35, loss 0.0653319, acc 1
2018-07-17T12:50:20.417115: step 36, loss 0.0313426, acc 1
2018-07-17T12:50:20.453171: step 37, loss 0.146171, acc 0.9375
2018-07-17T12:50:20.487038: step 38, loss 0.00167279, acc 1
2018-07-17T12:50:20.506637: step 39, loss 0.000946642, acc 1
2018-07-17T12:50:20.538620: step 40, loss 0.0704363, acc 0.9375
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-40

2018-07-17T12:50:21.343399: step 41, loss 0.136071, acc 0.9375
2018-07-17T12:50:21.365770: step 42, loss 0.003333, acc 1
2018-07-17T12:50:21.398990: step 43, loss 0.205801, acc 0.9375
2018-07-17T12:50:21.431182: step 44, loss 0.0109692, acc 1
2018-07-17T12:50:21.452166: step 45, loss 0.0106078, acc 1
2018-07-17T12:50:21.480944: step 46, loss 0.0140635, acc 1
2018-07-17T12:50:21.507231: step 47, loss 0.0857912, acc 0.9375
2018-07-17T12:50:21.534405: step 48, loss 0.00099945, acc 1
2018-07-17T12:50:21.567592: step 49, loss 0.0231086, acc 1
2018-07-17T12:50:21.601497: step 50, loss 0.0295547, acc 1

Evaluation:
2018-07-17T12:50:21.649634: step 50, loss 0.61867, acc 0.5

Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-50

2018-07-17T12:50:22.228763: step 51, loss 0.00117847, acc 1
2018-07-17T12:50:22.269567: step 52, loss 0.223278, acc 0.9375
2018-07-17T12:50:22.305247: step 53, loss 0.0976025, acc 0.9375
2018-07-17T12:50:22.326180: step 54, loss 0.000503786, acc 1
2018-07-17T12:50:22.353979: step 55, loss 0.00657612, acc 1
2018-07-17T12:50:22.384410: step 56, loss 0.0556485, acc 0.9375
2018-07-17T12:50:22.406380: step 57, loss 0.00639356, acc 1
2018-07-17T12:50:22.442191: step 58, loss 0.00145335, acc 1
2018-07-17T12:50:22.474840: step 59, loss 0.00694554, acc 1
2018-07-17T12:50:22.496092: step 60, loss 0.00047052, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-60

2018-07-17T12:50:23.174194: step 61, loss 0.00674976, acc 1
2018-07-17T12:50:23.200737: step 62, loss 0.165216, acc 0.9375
2018-07-17T12:50:23.227141: step 63, loss 0.0424605, acc 1
2018-07-17T12:50:23.259323: step 64, loss 0.0182473, acc 1
2018-07-17T12:50:23.290329: step 65, loss 0.00647471, acc 1
2018-07-17T12:50:23.307726: step 66, loss 0.106113, acc 1
2018-07-17T12:50:23.343815: step 67, loss 0.138087, acc 0.9375
2018-07-17T12:50:23.375219: step 68, loss 0.00412388, acc 1
2018-07-17T12:50:23.402756: step 69, loss 8.47804e-05, acc 1
2018-07-17T12:50:23.433260: step 70, loss 0.00841947, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-70

2018-07-17T12:50:24.159713: step 71, loss 0.162873, acc 0.9375
2018-07-17T12:50:24.183714: step 72, loss 0.000946178, acc 1
2018-07-17T12:50:24.214895: step 73, loss 0.0116328, acc 1
2018-07-17T12:50:24.254012: step 74, loss 0.0134039, acc 1
2018-07-17T12:50:24.281589: step 75, loss 0.000177055, acc 1
2018-07-17T12:50:24.313433: step 76, loss 0.026167, acc 1
2018-07-17T12:50:24.348626: step 77, loss 0.00452198, acc 1
2018-07-17T12:50:24.369992: step 78, loss 0.15376, acc 1
2018-07-17T12:50:24.408768: step 79, loss 0.00279373, acc 1
2018-07-17T12:50:24.439318: step 80, loss 0.00105605, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-80

2018-07-17T12:50:25.021833: step 81, loss 0.00141281, acc 1
2018-07-17T12:50:25.065679: step 82, loss 0.0224302, acc 1
2018-07-17T12:50:25.091999: step 83, loss 0.0217885, acc 1
2018-07-17T12:50:25.114858: step 84, loss 0.00011293, acc 1
2018-07-17T12:50:25.147380: step 85, loss 0.00103493, acc 1
2018-07-17T12:50:25.180024: step 86, loss 0.101926, acc 0.9375
2018-07-17T12:50:25.198796: step 87, loss 0.00609453, acc 1
2018-07-17T12:50:25.230901: step 88, loss 0.0313909, acc 1
2018-07-17T12:50:25.269924: step 89, loss 0.0656676, acc 0.9375
2018-07-17T12:50:25.291651: step 90, loss 0.0046512, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-90

2018-07-17T12:50:26.061857: step 91, loss 0.0325454, acc 1
2018-07-17T12:50:26.096066: step 92, loss 0.00102838, acc 1
2018-07-17T12:50:26.120884: step 93, loss 0.000756332, acc 1
2018-07-17T12:50:26.150987: step 94, loss 0.0050545, acc 1
2018-07-17T12:50:26.181517: step 95, loss 0.0877863, acc 0.9375
2018-07-17T12:50:26.208680: step 96, loss 2.89081e-06, acc 1
2018-07-17T12:50:26.240245: step 97, loss 0.0318598, acc 1
2018-07-17T12:50:26.273835: step 98, loss 0.00399157, acc 1
2018-07-17T12:50:26.295012: step 99, loss 5.37902e-05, acc 1
2018-07-17T12:50:26.325589: step 100, loss 0.159579, acc 0.875

Evaluation:
2018-07-17T12:50:26.339482: step 100, loss 1.5478, acc 0.5

Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-100

2018-07-17T12:50:27.107404: step 101, loss 0.0145354, acc 1
2018-07-17T12:50:27.128314: step 102, loss 0.00481383, acc 1
2018-07-17T12:50:27.157618: step 103, loss 0.0167086, acc 1
2018-07-17T12:50:27.192246: step 104, loss 0.0057864, acc 1
2018-07-17T12:50:27.212449: step 105, loss 0.000116637, acc 1
2018-07-17T12:50:27.237347: step 106, loss 0.00305927, acc 1
2018-07-17T12:50:27.268247: step 107, loss 0.00576753, acc 1
2018-07-17T12:50:27.292599: step 108, loss 1.06741, acc 0.75
2018-07-17T12:50:27.329032: step 109, loss 0.0105429, acc 1
2018-07-17T12:50:27.363193: step 110, loss 0.000878588, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-110

2018-07-17T12:50:28.097491: step 111, loss 0.00124058, acc 1
2018-07-17T12:50:28.133678: step 112, loss 0.0146892, acc 1
2018-07-17T12:50:28.166181: step 113, loss 0.0465526, acc 0.9375
2018-07-17T12:50:28.194480: step 114, loss 2.4854e-05, acc 1
2018-07-17T12:50:28.237923: step 115, loss 0.41083, acc 0.9375
2018-07-17T12:50:28.287654: step 116, loss 0.0392655, acc 1
2018-07-17T12:50:28.313023: step 117, loss 0.0550523, acc 1
2018-07-17T12:50:28.349860: step 118, loss 5.60632e-05, acc 1
2018-07-17T12:50:28.377960: step 119, loss 0.0106731, acc 1
2018-07-17T12:50:28.402412: step 120, loss 0.0050187, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-120

2018-07-17T12:50:29.118644: step 121, loss 0.0124171, acc 1
2018-07-17T12:50:29.156779: step 122, loss 0.0047396, acc 1
2018-07-17T12:50:29.175292: step 123, loss 0.00605648, acc 1
2018-07-17T12:50:29.205534: step 124, loss 0.00101442, acc 1
2018-07-17T12:50:29.239611: step 125, loss 0.0964494, acc 0.9375
2018-07-17T12:50:29.262043: step 126, loss 8.97041e-06, acc 1
2018-07-17T12:50:29.289463: step 127, loss 0.12967, acc 0.9375
2018-07-17T12:50:29.326989: step 128, loss 0.00262968, acc 1
2018-07-17T12:50:29.349058: step 129, loss 0.0017773, acc 1
2018-07-17T12:50:29.382361: step 130, loss 0.160277, acc 0.875
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-130

2018-07-17T12:50:30.075512: step 131, loss 0.000674686, acc 1
2018-07-17T12:50:30.095028: step 132, loss 7.30147e-06, acc 1
2018-07-17T12:50:30.125789: step 133, loss 0.000971052, acc 1
2018-07-17T12:50:30.158119: step 134, loss 0.00710973, acc 1
2018-07-17T12:50:30.178957: step 135, loss 2.9741e-05, acc 1
2018-07-17T12:50:30.211240: step 136, loss 0.00193627, acc 1
2018-07-17T12:50:30.238892: step 137, loss 0.147694, acc 0.9375
2018-07-17T12:50:30.262586: step 138, loss 1.74934e-05, acc 1
2018-07-17T12:50:30.292172: step 139, loss 0.0001395, acc 1
2018-07-17T12:50:30.326934: step 140, loss 0.0081063, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-140

2018-07-17T12:50:31.037314: step 141, loss 9.82487e-05, acc 1
2018-07-17T12:50:31.077853: step 142, loss 0.000803737, acc 1
2018-07-17T12:50:31.108607: step 143, loss 0.00264228, acc 1
2018-07-17T12:50:31.130941: step 144, loss 4.11251e-05, acc 1
2018-07-17T12:50:31.164802: step 145, loss 0.000886452, acc 1
2018-07-17T12:50:31.195235: step 146, loss 0.104255, acc 0.9375
2018-07-17T12:50:31.217080: step 147, loss 0.00104998, acc 1
2018-07-17T12:50:31.249713: step 148, loss 0.00400864, acc 1
2018-07-17T12:50:31.285729: step 149, loss 0.00520336, acc 1
2018-07-17T12:50:31.306065: step 150, loss 5.00036e-05, acc 1

Evaluation:
2018-07-17T12:50:31.319145: step 150, loss 1.39053, acc 0.5

Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-150

2018-07-17T12:50:32.052247: step 151, loss 0.00473939, acc 1
2018-07-17T12:50:32.083679: step 152, loss 0.000125092, acc 1
2018-07-17T12:50:32.104684: step 153, loss 2.78343e-05, acc 1
2018-07-17T12:50:32.134761: step 154, loss 0.0105959, acc 1
2018-07-17T12:50:32.164357: step 155, loss 0.0157406, acc 1
2018-07-17T12:50:32.189043: step 156, loss 1.37091e-06, acc 1
2018-07-17T12:50:32.219195: step 157, loss 0.00558183, acc 1
2018-07-17T12:50:32.256455: step 158, loss 0.00750288, acc 1
2018-07-17T12:50:32.276298: step 159, loss 0.000279946, acc 1
2018-07-17T12:50:32.308054: step 160, loss 0.0325295, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-160

2018-07-17T12:50:32.898420: step 161, loss 0.000102518, acc 1
2018-07-17T12:50:32.922053: step 162, loss 0.0776015, acc 1
2018-07-17T12:50:32.956751: step 163, loss 0.00459755, acc 1
2018-07-17T12:50:32.990134: step 164, loss 0.00025535, acc 1
2018-07-17T12:50:33.008648: step 165, loss 0.000151916, acc 1
2018-07-17T12:50:33.043261: step 166, loss 0.00117209, acc 1
2018-07-17T12:50:33.072663: step 167, loss 0.000375399, acc 1
2018-07-17T12:50:33.097365: step 168, loss 0.00384399, acc 1
2018-07-17T12:50:33.132636: step 169, loss 0.000853003, acc 1
2018-07-17T12:50:33.163591: step 170, loss 0.000741506, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-170

2018-07-17T12:50:33.887897: step 171, loss 4.3748e-05, acc 1
2018-07-17T12:50:33.922554: step 172, loss 0.000437763, acc 1
2018-07-17T12:50:33.948228: step 173, loss 0.00167811, acc 1
2018-07-17T12:50:33.975994: step 174, loss 0.0016807, acc 1
2018-07-17T12:50:34.007624: step 175, loss 0.0143209, acc 1
2018-07-17T12:50:34.036386: step 176, loss 0.000221401, acc 1
2018-07-17T12:50:34.058708: step 177, loss 4.47033e-06, acc 1
2018-07-17T12:50:34.088095: step 178, loss 0.000946129, acc 1
2018-07-17T12:50:34.123685: step 179, loss 9.40428e-05, acc 1
2018-07-17T12:50:34.144032: step 180, loss 0.00101096, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-180

2018-07-17T12:50:34.875974: step 181, loss 0.00102984, acc 1
2018-07-17T12:50:34.914026: step 182, loss 0.00120199, acc 1
2018-07-17T12:50:34.940394: step 183, loss 0.00145905, acc 1
2018-07-17T12:50:34.974345: step 184, loss 0.00295361, acc 1
2018-07-17T12:50:35.017162: step 185, loss 0.00809052, acc 1
2018-07-17T12:50:35.039141: step 186, loss 0.00275802, acc 1
2018-07-17T12:50:35.076362: step 187, loss 0.000861469, acc 1
2018-07-17T12:50:35.112164: step 188, loss 0.00607823, acc 1
2018-07-17T12:50:35.139464: step 189, loss 2.42282e-05, acc 1
2018-07-17T12:50:35.172686: step 190, loss 0.00117959, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-190

2018-07-17T12:50:35.926894: step 191, loss 0.558183, acc 0.9375
2018-07-17T12:50:35.947773: step 192, loss 0.00278374, acc 1
2018-07-17T12:50:35.984258: step 193, loss 0.0376947, acc 1
2018-07-17T12:50:36.020802: step 194, loss 0.000706934, acc 1
2018-07-17T12:50:36.045182: step 195, loss 0.00068634, acc 1
2018-07-17T12:50:36.079785: step 196, loss 0.000398576, acc 1
2018-07-17T12:50:36.113529: step 197, loss 0.0161698, acc 1
2018-07-17T12:50:36.139003: step 198, loss 5.27157e-05, acc 1
2018-07-17T12:50:36.179090: step 199, loss 0.0118596, acc 1
2018-07-17T12:50:36.215312: step 200, loss 2.1382e-05, acc 1

Evaluation:
2018-07-17T12:50:36.228721: step 200, loss 1.33603, acc 0.5

Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-200

2018-07-17T12:50:36.894947: step 201, loss 0.000710224, acc 1
2018-07-17T12:50:36.925813: step 202, loss 6.0036e-05, acc 1
2018-07-17T12:50:36.954509: step 203, loss 8.48363e-05, acc 1
2018-07-17T12:50:36.972378: step 204, loss 6.17757e-05, acc 1
2018-07-17T12:50:37.005651: step 205, loss 0.0126738, acc 1
2018-07-17T12:50:37.038296: step 206, loss 0.000356576, acc 1
2018-07-17T12:50:37.058791: step 207, loss 3.79371e-05, acc 1
2018-07-17T12:50:37.089447: step 208, loss 0.00163153, acc 1
2018-07-17T12:50:37.120863: step 209, loss 0.00132901, acc 1
2018-07-17T12:50:37.142918: step 210, loss 0.00408936, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-210

2018-07-17T12:50:37.737280: step 211, loss 0.000315054, acc 1
2018-07-17T12:50:37.772644: step 212, loss 0.00619656, acc 1
2018-07-17T12:50:37.794743: step 213, loss 0.00112361, acc 1
2018-07-17T12:50:37.823634: step 214, loss 0.000402449, acc 1
2018-07-17T12:50:37.854837: step 215, loss 0.00295223, acc 1
2018-07-17T12:50:37.876860: step 216, loss 8.64266e-07, acc 1
2018-07-17T12:50:37.905037: step 217, loss 4.53469e-05, acc 1
2018-07-17T12:50:37.938079: step 218, loss 0.0012262, acc 1
2018-07-17T12:50:37.960420: step 219, loss 1.25169e-06, acc 1
2018-07-17T12:50:37.990084: step 220, loss 0.00728096, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-220

2018-07-17T12:50:38.701048: step 221, loss 4.81366e-05, acc 1
2018-07-17T12:50:38.718637: step 222, loss 0.000113614, acc 1
2018-07-17T12:50:38.753626: step 223, loss 0.000123981, acc 1
2018-07-17T12:50:38.783162: step 224, loss 0.00819612, acc 1
2018-07-17T12:50:38.802476: step 225, loss 0.0181919, acc 1
2018-07-17T12:50:38.837013: step 226, loss 4.59277e-05, acc 1
2018-07-17T12:50:38.865864: step 227, loss 0.000278651, acc 1
2018-07-17T12:50:38.889613: step 228, loss 0.000593096, acc 1
2018-07-17T12:50:38.925397: step 229, loss 0.00220542, acc 1
2018-07-17T12:50:38.959038: step 230, loss 0.000334237, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-230

2018-07-17T12:50:39.752054: step 231, loss 1.55863e-05, acc 1
2018-07-17T12:50:39.792898: step 232, loss 0.000514566, acc 1
2018-07-17T12:50:39.828052: step 233, loss 0.000120366, acc 1
2018-07-17T12:50:39.872692: step 234, loss 0.00189548, acc 1
2018-07-17T12:50:39.951759: step 235, loss 0.00235935, acc 1
2018-07-17T12:50:40.017418: step 236, loss 0.000303428, acc 1
2018-07-17T12:50:40.061143: step 237, loss 5.58759e-05, acc 1
2018-07-17T12:50:40.135631: step 238, loss 0.000106251, acc 1
2018-07-17T12:50:40.206905: step 239, loss 0.00678203, acc 1
2018-07-17T12:50:40.250772: step 240, loss 0.000130114, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-240

2018-07-17T12:50:41.294001: step 241, loss 0.000557931, acc 1
2018-07-17T12:50:41.359115: step 242, loss 0.00229932, acc 1
2018-07-17T12:50:41.409257: step 243, loss 0.00018555, acc 1
2018-07-17T12:50:41.482125: step 244, loss 0.000507287, acc 1
2018-07-17T12:50:41.549149: step 245, loss 0.0027274, acc 1
2018-07-17T12:50:41.600565: step 246, loss 0.000139832, acc 1
2018-07-17T12:50:41.664167: step 247, loss 0.0726783, acc 0.9375
2018-07-17T12:50:41.744434: step 248, loss 0.00376643, acc 1
2018-07-17T12:50:41.792030: step 249, loss 1.90735e-06, acc 1
2018-07-17T12:50:41.858185: step 250, loss 0.000956056, acc 1

Evaluation:
2018-07-17T12:50:41.889165: step 250, loss 1.26578, acc 0.5

Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-250

2018-07-17T12:50:42.886779: step 251, loss 0.000984867, acc 1
2018-07-17T12:50:42.910410: step 252, loss 9.53673e-07, acc 1
2018-07-17T12:50:42.945702: step 253, loss 3.08198e-05, acc 1
2018-07-17T12:50:42.980128: step 254, loss 0.000910498, acc 1
2018-07-17T12:50:43.002753: step 255, loss 0.000217977, acc 1
2018-07-17T12:50:43.031470: step 256, loss 0.00241059, acc 1
2018-07-17T12:50:43.086570: step 257, loss 4.53737e-05, acc 1
2018-07-17T12:50:43.118241: step 258, loss 4.76837e-07, acc 1
2018-07-17T12:50:43.179342: step 259, loss 0.00095115, acc 1
2018-07-17T12:50:43.221097: step 260, loss 0.000334054, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-260

2018-07-17T12:50:43.988068: step 261, loss 1.19209e-06, acc 1
2018-07-17T12:50:44.027739: step 262, loss 0.000260882, acc 1
2018-07-17T12:50:44.061789: step 263, loss 4.89492e-06, acc 1
2018-07-17T12:50:44.080467: step 264, loss 2.77161e-06, acc 1
2018-07-17T12:50:44.109152: step 265, loss 0.00120598, acc 1
2018-07-17T12:50:44.146463: step 266, loss 0.00053431, acc 1
2018-07-17T12:50:44.165550: step 267, loss 1.51991e-06, acc 1
2018-07-17T12:50:44.200781: step 268, loss 0.00207289, acc 1
2018-07-17T12:50:44.239208: step 269, loss 0.000321052, acc 1
2018-07-17T12:50:44.271513: step 270, loss 2.37816e-05, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-270

2018-07-17T12:50:45.024366: step 271, loss 0.071366, acc 0.9375
2018-07-17T12:50:45.064950: step 272, loss 0.00909953, acc 1
2018-07-17T12:50:45.093400: step 273, loss 3.84447e-06, acc 1
2018-07-17T12:50:45.130015: step 274, loss 1.23229e-05, acc 1
2018-07-17T12:50:45.165498: step 275, loss 0.000169445, acc 1
2018-07-17T12:50:45.193510: step 276, loss 8.9407e-08, acc 1
2018-07-17T12:50:45.229302: step 277, loss 0.000166116, acc 1
2018-07-17T12:50:45.265136: step 278, loss 0.00114614, acc 1
2018-07-17T12:50:45.291055: step 279, loss 0.000423196, acc 1
2018-07-17T12:50:45.324566: step 280, loss 0.000594193, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-280

2018-07-17T12:50:45.969937: step 281, loss 0.000632599, acc 1
2018-07-17T12:50:45.995033: step 282, loss 1.09075e-05, acc 1
2018-07-17T12:50:46.026718: step 283, loss 0.0002061, acc 1
2018-07-17T12:50:46.058380: step 284, loss 0.000349461, acc 1
2018-07-17T12:50:46.079552: step 285, loss 0.000183605, acc 1
2018-07-17T12:50:46.110456: step 286, loss 0.0012259, acc 1
2018-07-17T12:50:46.142603: step 287, loss 0.000419943, acc 1
2018-07-17T12:50:46.163611: step 288, loss 0.0165727, acc 1
2018-07-17T12:50:46.198652: step 289, loss 5.74187e-05, acc 1
2018-07-17T12:50:46.230457: step 290, loss 0.00248232, acc 1
Saved model checkpoint to C:\Users\tjsch\Desktop\DeepLearning_Lesson5\DeepLearning_Lesson5\runs\1531849815\checkpoints\model-290

2018-07-17T12:50:46.886471: step 291, loss 0.000600631, acc 1
2018-07-17T12:50:46.918183: step 292, loss 0.0220522, acc 1
2018-07-17T12:50:46.954875: step 293, loss 1.23302e-05, acc 1
2018-07-17T12:50:46.973947: step 294, loss 6.04985e-06, acc 1
2018-07-17T12:50:47.009349: step 295, loss 3.61609e-05, acc 1
2018-07-17T12:50:47.044834: step 296, loss 0.00121684, acc 1
2018-07-17T12:50:47.070174: step 297, loss 2.08616e-07, acc 1
2018-07-17T12:50:47.103958: step 298, loss 1.61896e-05, acc 1
2018-07-17T12:50:47.150363: step 299, loss 0.00651284, acc 1
2018-07-17T12:50:47.180877: step 300, loss 0.000200749, acc 1